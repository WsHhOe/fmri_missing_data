{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "from fnmatch import fnmatch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class brain:\n",
    "\n",
    "    def __init__(self,path):\n",
    "        \n",
    "            #turn the matrix it ones to mark where activation is\n",
    "        def activationpts(f):\n",
    "            '''\n",
    "            function for turning activation points into binary values\n",
    "            \n",
    "            f (array/array-like) ; array of matrix of brain activation data\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            return np.sign(np.abs(f))\n",
    "    \n",
    "         #load files through directory so we can link to subj ID\n",
    "        def get_files(direct):\n",
    "            \n",
    "            #load all niis in path\n",
    "            fels=[os.path.join(direct, k) for k in os.listdir(direct) if re.search('beta.*.nii', k) ]\n",
    "            \n",
    "            \n",
    "            #pull affine and head for zero-eth element in the list\n",
    "            affine=nib.load(fels[0]).affine\n",
    "            hdr=nib.load(fels[0]).header\n",
    "            \n",
    "            #read them as niis and pull data matrix\n",
    "            fels=np.array([nib.load(f).get_data() for f in fels])\n",
    "            \n",
    "            fels=activationpts(np.sum(fels, axis=0))\n",
    "            fels[np.isnan(fels)]=0\n",
    "            return {'data': fels, 'affines': affine, 'header': hdr}\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.path = path\n",
    "        \n",
    "        #dictionary linking subject ID to subject data\n",
    "        self.data={}\n",
    "        dirs = os.listdir(path)\n",
    "        for d in dirs:\n",
    "            self.data[d]=get_files(os.path.join(path, d))\n",
    "    \n",
    "        #merge nii images\n",
    "        self.data['Group']={'data':'', 'affines': '', 'header': '' }\n",
    "        self.data['Group']['data']=np.sum(np.array(\n",
    "            [self.data[sub]['data'] for sub in self.data.keys() if sub !='Group']), axis=0)\n",
    "        self.data['Group']['affines']=self.data[list(self.data.keys())[0]]['affines']\n",
    "        self.data['Group']['header']=self.data[list(self.data.keys())[0]]['header']\n",
    "        \n",
    "      \n",
    "\n",
    "    def write_map(self, data='Group', path=None, fileName='Nii1.nii'):\n",
    "        \n",
    "        wrt_file=nib.Nifti1Image(self.data[data]['data'], self.data[data]['affines'],\n",
    "                                 self.data[data]['header'])\n",
    "        if path:\n",
    "            wrt_file.to_filename(os.path.join(path, fileName))\n",
    "        else:\n",
    "            wrt_file.to_filename(os.path.join(self.path, fileName))\n",
    "            \n",
    "   \n",
    "    def write_mask(self, threshold, data='Group', path=None, fileName='mask.nii'):\n",
    "        #pull in self.data for readability\n",
    "        tr_data=self.data[data]['data']\n",
    "        #zero out sub threshold values then convert to ones\n",
    "        tr_data[tr_data<threshold]=0\n",
    "        tr_data=np.sign(tr_data)\n",
    "        \n",
    "        wrt_file=nib.Nifti1Image(tr_data, self.data[data]['affines'],\n",
    "                                 self.data[data]['header'])\n",
    "\n",
    "        if path:\n",
    "            wrt_file.to_filename(os.path.join(path, fileName))\n",
    "        else:\n",
    "            wrt_file.to_filename(os.path.join(self.path, fileName))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    #finding missing data and pair them with subject ID\n",
    "    #dirs = os.listdir(self.path)\n",
    "    #for d in dirs:\n",
    "        #print (self.data[d])\n",
    "    def datapt (self,x,y,z):\n",
    "        names=list(self.data.keys())\n",
    "        names.remove('Group')\n",
    "        missinglist = []\n",
    "        for ID in names: \n",
    "            if self.data[ID]['data'][x][y][z] == 0:\n",
    "                missinglist.append(ID)\n",
    "            else:\n",
    "                pass\n",
    "        return (missinglist)\n",
    "\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=brain('/mnt/datashare/Pr1.LL/Analysis/Analysis_level1/uniVar_opEv[Final choosen_minus_50dt]')\n",
    "#k.write_mask(data='Group', threshold=38, path='/mnt/datashare/Pr1.LL/Analysis/', fileName='mask_thresh38.nii')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.write_mask(data='Group', threshold=1, path='/mnt/datashare/Pr1.LL/Analysis/', fileName='mask_thresh1.nii')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
